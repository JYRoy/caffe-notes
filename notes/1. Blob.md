# Blob

[TOC]

## Blob

Blob是caffe中的数据类，类似现代深度学习框架中的Tensor类，根据类图我们可以看到，由Blob、SyncedMemory一起来进行数据管理。

Blob只是一个wrapper类，真正的数据指针和数据的D2H、H2D操作都是通过SyncedMemory类来管理和实现的。

我们通过头文件来学习Blob类中的具体内容，只保留头文件中的核心部分。

```cpp
namespace caffe {
template <typename Dtype>
class Blob {
 public:
  Blob(): data_(), diff_(), count_(0), capacity_(0) {}

  // 实例化需要设置NCHW
  explicit Blob(const int num, const int channels, const int height, const int width);
  explicit Blob(const vector<int>& shape);

  // 用于数据访问的接口，cpu_data()、gpu_data()、cpu_diff()、gpu_diff()直接返回SyncedMemory中的数据指针Dtype*，因为是const pointer，所以不能指向新的对象。
  const Dtype* cpu_data() const;
  void set_cpu_data(Dtype* data);
  const int* gpu_shape() const;
  const Dtype* gpu_data() const;
  void set_gpu_data(Dtype* data);
  const Dtype* cpu_diff() const;
  const Dtype* gpu_diff() const;

  // 同上，返回SyncedMemory中记录的数据指针，mutable这里含义就是内容是否可以修改，相当于对于用户的约束，因此不加const约束
  Dtype* mutable_cpu_data();
  Dtype* mutable_gpu_data();
  Dtype* mutable_cpu_diff();
  Dtype* mutable_gpu_diff();
  void Update();

  void FromProto(const BlobProto& proto, bool reshape = true);
  void ToProto(BlobProto* proto, bool write_diff = false) const;

 protected:
  shared_ptr<SyncedMemory> data_;  // 记录数据的syncedmemory对象
  shared_ptr<SyncedMemory> diff_;  // 记录梯度的syncedmemory对象
  shared_ptr<SyncedMemory> shape_data_;
  vector<int> shape_;  // <N, C, H, W>数据
  int count_;  // N * C * H *　W
  int capacity_;
};
}
```

## SyncedMemory

SyncedMemory类是数据的实际管理者。对于同一份数据，会有在cpu上的版本和在gpu上的版本，syncedhead表明了当前的数据状态，这里设计了一个完整的状态机

- UNINITIALIZED：当前数据对象没有进行过初始化，没有任何已分配的内存或者显存空间；
- HEAD_AT_CPU：目前在内存上的数据内容是最新的，不对显存上的数据内容做任何保证；
- HEAD_AT_GPU：目前在显存上的数据内容是最新的，不对内存上的数据内容做任何保证；
- SYNCED：内存和显存上的数据是一致的；

状态机的变化具体如下：

![](./assets/3.png)

```cpp
// 负责caffe底层的数据的内存管理
class SyncedMemory {
 public:
  SyncedMemory();
  explicit SyncedMemory(size_t size);
  ~SyncedMemory();
  const void* cpu_data();  // 获取cpu上的data地址
  void set_cpu_data(void* data);  // 将数据设置到一块新的cpu内存区域中，将原本的地址释放
  const void* gpu_data();  // 获取gpu上的data地址
  void set_gpu_data(void* data);  // 将数据设置到一块新的gpu内存区域中，将原本的地址释放
  void* mutable_cpu_data();
  void* mutable_gpu_data();
  enum SyncedHead { UNINITIALIZED, HEAD_AT_CPU, HEAD_AT_GPU, SYNCED };  // 数据同步状态，本类中操作数据的方法会根据synchead来进行逻辑判断
  SyncedHead head() const { return head_; }
  size_t size() const { return size_; }

#ifndef CPU_ONLY
  void async_gpu_push(const cudaStream_t& stream);
#endif

 private:
  void check_device();

  void to_cpu();
  void to_gpu();
  void* cpu_ptr_;  // cpu内存地址，可以由对象自己分配，也可以外部指定
  void* gpu_ptr_;  // gpu内存地址，可以由对象自己分配，也可以外部指定
  size_t size_;  // 数据大小
  SyncedHead head_;  // 数据同步状态
  bool own_cpu_data_;  // 指示是否由对象内部调用CaffeMoallocHost分配的内存
  bool cpu_malloc_use_cuda_;  // 指示是否使用cudaMallocHost分配pinned memory
  bool own_gpu_data_;  // 指示是否由对象内部调用cudaMalloc分配的显存
  int device_;
  DISABLE_COPY_AND_ASSIGN(SyncedMemory);
};  // class SyncedMemory
```

## Implementation

接下来关注一下重点的函数的实现，因为Blob类是SyncedMemory类的一个wrapper，所以我们重点关注SyncedMemory的函数，也就是上面自动状态机的几个函数和用于内存显存分配的函数。

### SyncedMemory构造和析构

SyncedMemory构造时head初始化为UNINITIALIZED，指示当前没有任何的数据并且没有分配过任何的显存、内存空间。如果要使用gpu，实例化时还会获取gpu device号。

```cpp
SyncedMemory::SyncedMemory(size_t size)
  : cpu_ptr_(NULL), gpu_ptr_(NULL), size_(size), head_(UNINITIALIZED),
    own_cpu_data_(false), cpu_malloc_use_cuda_(false), own_gpu_data_(false) {
#ifndef CPU_ONLY
#ifdef DEBUG
  CUDA_CHECK(cudaGetDevice(&device_));
#endif
#endif
}
```

析构时自然就是要释放分配的内存、显存，显存释放直接嗲用cudaFree，内存释放使用了Caffe封装的CaffeFreeHost方法。

```cpp
SyncedMemory::~SyncedMemory() {
  check_device();
  if (cpu_ptr_ && own_cpu_data_) {
    CaffeFreeHost(cpu_ptr_, cpu_malloc_use_cuda_);
  }

#ifndef CPU_ONLY
  if (gpu_ptr_ && own_gpu_data_) {
    CUDA_CHECK(cudaFree(gpu_ptr_));
  }
#endif  // CPU_ONLY
}
```

### CaffeMalloc/FreeHost

Caffe封装分配和释放内存、显存这一层其实也比较朴素，只是为了对外透明计算平台差异，这种统一的封装还是做异构支持比较常见的方式，对用户屏蔽不同的平台，只暴露指针。

cudaMallocHost分配的是pin memory。和cudaMalloc做区分。

```cpp
inline void CaffeMallocHost(void** ptr, size_t size, bool* use_cuda) {
#ifndef CPU_ONLY
  if (Caffe::mode() == Caffe::GPU) {
    CUDA_CHECK(cudaMallocHost(ptr, size));
    *use_cuda = true;
    return;
  }
#endif
#ifdef USE_MKL
  *ptr = mkl_malloc(size ? size:1, 64);
#else
  *ptr = malloc(size);
#endif
  *use_cuda = false;
  CHECK(*ptr) << "host allocation of size " << size << " failed";
}

inline void CaffeFreeHost(void* ptr, bool use_cuda) {
#ifndef CPU_ONLY
  if (use_cuda) {
    CUDA_CHECK(cudaFreeHost(ptr));
    return;
  }
#endif
#ifdef USE_MKL
  mkl_free(ptr);
#else
  free(ptr);
#endif
}
```

### CPU

to_cpu和mutable_cpu_data是状态变为cpu的关键方法。

对于to_cpu，有两个状态变化路径：

- UNINTIALIZED -> malloc() -> memset() -> HEAD_AT_GPU、own_cpu_data
- HEAD_AT_GPU
  - HEAD_AT_GPU -> malloc() -> cudaMemcpyDtoH() -> HEAD_AT_GPU、own_cpu_data
  - HEAD_AT_GPU -> cudaMemcpyDtoH() -> SYNCED

```cpp
inline void SyncedMemory::to_cpu() {
  check_device();
  switch (head_) {
  case UNINITIALIZED:  // 数据没有初始化
    CaffeMallocHost(&cpu_ptr_, size_, &cpu_malloc_use_cuda_);
    caffe_memset(size_, 0, cpu_ptr_);
    head_ = HEAD_AT_CPU;
    own_cpu_data_ = true;  // 由CaffeMalocHost自己开辟的内存，则设置为true
    break;
  case HEAD_AT_GPU:  // 数据在显存上
#ifndef CPU_ONLY
    if (cpu_ptr_ == NULL) {  // 没有分配内存地址时先进行分配
      CaffeMallocHost(&cpu_ptr_, size_, &cpu_malloc_use_cuda_);
      own_cpu_data_ = true;
    }
    caffe_gpu_memcpy(size_, gpu_ptr_, cpu_ptr_);  // 当数据在显存上时，从显存memcpy到内存
    head_ = SYNCED;  // 因为此时cpu和gpu上的数据内容时一致的，所以状态是SYNCED
#else
    NO_GPU;
#endif
    break;
  case HEAD_AT_CPU:
  case SYNCED:
    break;
  }
}
```

对于mutable_cpu_data，也有两个路径，不过都是使用to_cpu来实现实际的内存空间申请和数据拷贝，也就是说，虽然该方法的命名方式虽然只是形容词＋名词的结构，但是语义上还是有拷贝的动作，且返回的指针也是可以修改指向的。

- SYNCED -> mutable_cpu_data -> HEAD_AT_CPU
- HEAD_AT_GPU -> mutable_cpu_data -> HEAD_AT_CPU

```cpp
void* SyncedMemory::mutable_cpu_data() {  // 非const
  check_device();
  to_cpu();
  head_ = HEAD_AT_CPU;
  return cpu_ptr_;
}
```

### GPU

和上面类似，to_gpu和mutable_gpu_data是状态变为gpu的关键方法。

- UNINITIALIZED -> cudaMalloc() -> memset() -> HEAD_AT_GPU、own_gpu_data
- HEAD_AT_CPU
  - HEAD_AT_CPU -> cudaMalloc() -> memcpy() -> HEAD_AT_GPU、own_gpu_data
  - HEAD_AT_CPU -> memcpy() -> SYNCED

```cpp
inline void SyncedMemory::to_gpu() {
  check_device();
#ifndef CPU_ONLY
  switch (head_) {
  case UNINITIALIZED:  // 数据没有初始化
    CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));  // 分配显存空间
    caffe_gpu_memset(size_, 0, gpu_ptr_);
    head_ = HEAD_AT_GPU;
    own_gpu_data_ = true;
    break;
  case HEAD_AT_CPU:
    if (gpu_ptr_ == NULL) {  // 没有gpu指针时分配显存空间
      CUDA_CHECK(cudaMalloc(&gpu_ptr_, size_));
      own_gpu_data_ = true;
    }
    caffe_gpu_memcpy(size_, cpu_ptr_, gpu_ptr_);  // 数据拷贝
    head_ = SYNCED;  // 因为此时cpu和gpu上的数据内容时一致的，所以状态是SYNCED
    break;
  case HEAD_AT_GPU:
  case SYNCED:
    break;
  }
#else
  NO_GPU;
#endif
}
```

```cpp
void* SyncedMemory::mutable_gpu_data() {
  check_device();
#ifndef CPU_ONLY
  to_gpu();
  head_ = HEAD_AT_GPU;
  return gpu_ptr_;
#else
  NO_GPU;
  return NULL;
#endif
}
```

从上面的代码中可以看到，SYNCED状态的逻辑，gpu->cpu、cpu->gpu后，两侧的数据内容是完全一致的，那么状态就是SYNCED的。对于mutable方法，因为返回的指针不是const的，所以指向的内存地址是可以被改变的，这个时候head是被标记为HEAD_AT_GPU、HEAD_AT_CPU，同时因为mutable方法不只是为了拷贝同步数据，所以状态最终不是SYNCED。
