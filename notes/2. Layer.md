# Layer

[TOC]

## Layer

Layer类是所有许多类的基类：data layer、neuron layer、common layer、vision layer、loss layer。

我们先来看一下Layer这个基类：

```cpp
template <typename Dtype>
class Layer {
 public:
  // Layer初始化。bottom：输入数据；top：输出数据
  void SetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {}

 protected:
  LayerParameter layer_param_;  // 参数的protobuf
  Phase phase_;  // 训练、推理
  vector<shared_ptr<Blob<Dtype> > > blobs_;  // 实际存储所有的可学习参数
  vector<bool> param_propagate_down_;  // 是否计算梯度
  vector<Dtype> loss_;  // 损失，只用于loss blob

  // 执行实际运算的方法，虚函数，需要子类实现，也就是每个OP的kernel
  virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) = 0;
  virtual void Forward_gpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {}
  virtual void Backward_cpu(const vector<Blob<Dtype>*>& top, const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) = 0;
  virtual void Backward_gpu(const vector<Blob<Dtype>*>& top, const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {}
}
```

## Implemention

### Layer构造和析构

构造函数，设置layer的参数blobs_

```cpp
explicit Layer(const LayerParameter& param): layer_param_(param) {
    phase_ = param.phase();
    if (layer_param_.blobs_size() > 0) {  // 判断是否存在可学习参数
        blobs_.resize(layer_param_.blobs_size());  // 因为一般存在很多可学习参数，所以要设置一下blobs_的大小
        for (int i = 0; i < layer_param_.blobs_size(); ++i) {  // 逐一读取参数信息
            blobs_[i].reset(new Blob<Dtype>());
            blobs_[i]->FromProto(layer_param_.blobs(i));
        }
    }
}
```

析构函数，是个虚函数，需要各个子类Layer自己去实现。

```cpp
virtual ~Layer() {}
```

### Layer Set Up

Layer提供了一个SetUp方法用于初始化Layer的配置，

```cpp
void SetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
    CheckBlobCounts(bottom, top);  // 检查top和bottom是不是正确的
    LayerSetUp(bottom, top);  // layer-specific的初始化方法
    Reshape(bottom, top);  // 设置top blobs和中间过程的一些缓冲区
    SetLossWeights(top);  // 设置loss weights
}
```

LayerSetUp是一个虚函数，也是需要各个子类Layer自己去实现。毕竟不同的类需要的东西不一样。

使用cudnn实现的OP需要创建一些Descriptor。某些需要设置一些常量参数等等。

```cpp
virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {}
```

### Forward

这里提供的Forward其实也是一个wrapper，真正的计算方法在Forward_cpu、Forward_gpu中实现。

```cpp
template <typename Dtype>
inline Dtype Layer<Dtype>::Forward(const vector<Blob<Dtype>*>& bottom,
    const vector<Blob<Dtype>*>& top) {
  Dtype loss = 0;
  Reshape(bottom, top);
  switch (Caffe::mode()) {
  case Caffe::CPU:
    Forward_cpu(bottom, top);  // 调用子类的实际cpu实现
    for (int top_id = 0; top_id < top.size(); ++top_id) {  // 遍历top blobs，如果是loss layer，输出的blob就是loss。
      if (!this->loss(top_id)) { continue; }  // 不是loss的话就直接跳过
      const int count = top[top_id]->count();
      const Dtype* data = top[top_id]->cpu_data();
      const Dtype* loss_weights = top[top_id]->cpu_diff();
      loss += caffe_cpu_dot(count, data, loss_weights);  // 根据loss weight计算总loss
    }
    break;
  case Caffe::GPU:
    Forward_gpu(bottom, top);  // 调用子类的实际gpu实现
#ifndef CPU_ONLY
    for (int top_id = 0; top_id < top.size(); ++top_id) {  // 这里的逻辑就是上面cpu部分是一样的了
      if (!this->loss(top_id)) { continue; }
      const int count = top[top_id]->count();
      const Dtype* data = top[top_id]->gpu_data();
      const Dtype* loss_weights = top[top_id]->gpu_diff();
      Dtype blob_loss = 0;
      caffe_gpu_dot(count, data, loss_weights, &blob_loss);
      loss += blob_loss;
    }
#endif
    break;
  default:
    LOG(FATAL) << "Unknown caffe mode.";
  }
  return loss;
}
```

### Backward

这里提供的Backward其实也是一个wrapper，真正的计算方法在Backward_cpu、Backward_gpu中实现。

```cpp
template <typename Dtype>
inline void Layer<Dtype>::Backward(const vector<Blob<Dtype>*>& top,
    const vector<bool>& propagate_down,  // 大小和bottom相同，指示是否要反向传播到对应的bottom blob
    const vector<Blob<Dtype>*>& bottom) {
  switch (Caffe::mode()) {
  case Caffe::CPU:
    Backward_cpu(top, propagate_down, bottom);
    break;
  case Caffe::GPU:
    Backward_gpu(top, propagate_down, bottom);
    break;
  default:
    LOG(FATAL) << "Unknown caffe mode.";
  }
}
```

## LayerFactory

caffe中Layer的实例化通过工厂模式来实现。工厂模式是一种创建对象的模式，根据我们的输入（通常是对象名、类型之类的）由工厂负责创建出对应的对象。

![](assets/4.%20caffe%20LayerFactory.png)

Caffe的Layer工厂包含两个类：LayerRegistry、LayerRegisterer和两个宏：REGISTER_LAYER_CREATOR、REGISTER_LAYER_CLASS。其中提供了一些静态方法来实现对象的注册和创建（其实不是创建，而是直接返回layer对象）。

在使用Layer工厂时，主要有两步操作：

1. 注册layer到工厂中：REGISTER_LAYER_CLASS -> REGISTER_LAYER_CREATOR -> LayerRegisterer -> LayerRegistry::AddCreator -> `std::map<string, Creator> CreatorRegistry`；
2. 从工厂中获取layer：有Nets来触发`layers_.push_back(LayerRegistry<Dtype>::CreateLayer(layer_param))`将所有的layer添加到网络中。

具体实现逻辑如下：

在caffe中所有的layer都通过REGISTER_LAYER_CLASS这个宏，例如：`REGISTER_LAYER_CLASS(ELU);`，注册ELU激活函数。

```cpp
#define REGISTER_LAYER_CLASS(type)                                             \
  template <typename Dtype>                                                    \
  shared_ptr<Layer<Dtype> > Creator_##type##Layer(const LayerParameter& param) \
  {                                                                            \
    return shared_ptr<Layer<Dtype> >(new type##Layer<Dtype>(param));           \
  }                                                                            \
  REGISTER_LAYER_CREATOR(type, Creator_##type##Layer)
```

```cpp
#define REGISTER_LAYER_CREATOR(type, creator)                                  \
  static LayerRegisterer<float> g_creator_f_##type(#type, creator<float>);     \
  static LayerRegisterer<double> g_creator_d_##type(#type, creator<double>)    \
```

这两个宏最终都会落脚到LayerRegisterer这个类，这个类接收两个参数：layer名字、子类对象指针。

```cpp
template <typename Dtype>
class LayerRegisterer {
 public:
  LayerRegisterer(const string& type,
                  shared_ptr<Layer<Dtype> > (*creator)(const LayerParameter&)) {
    LayerRegistry<Dtype>::AddCreator(type, creator);
  }
};
```

这里面调用AddCreator方法，将layer对象添加到一个map中。

```cpp
static void AddCreator(const string& type, Creator creator) {
    CreatorRegistry& registry = Registry();
    registry[type] = creator;
}

static CreatorRegistry& Registry() {
    static CreatorRegistry* g_registry_ = new CreatorRegistry();
    return *g_registry_;
}

typedef std::map<string, Creator> CreatorRegistry;  // 存储layer名到对象的映射
```

我们在实际使用layer的时候，因为前面以及注册到map中了，所以只要根据参数返回对应的对象就可以了。具体实现是CreateLayer方法。

```cpp
static shared_ptr<Layer<Dtype> > CreateLayer(const LayerParameter& param) {
  const string& type = param.type();  // layer名字
  CreatorRegistry& registry = Registry();  // 返回map
  return registry[type](param);  // 根据type返回对象
}
```
